# Chenfei WU (吴晨飞)

[Google Scholar](https://scholar.google.com/citations?hl=zh-CN&user=1YlFL5UAAAAJ) \| [Github](https://github.com/chenfei-wu) \| [LinkedIn](https://www.linkedin.com/in/chenfei-wu-544986167/) \|[Twitter](https://x.com/wu_chenfei)\| [Work Email: fulai.hr@alibaba-inc.com](fulai.hr@alibaba-inc.com) \|[Personal Email](Personal Email: cqwuchenfei@163.com)

Chenfei Wu received his Ph.D. from Beijing University of Posts and Telecommunications, and is currently a senior expert at Tongyi Lab, Alibaba. His research focuses on large model pretraining, multimodal understanding, and generation. His main research includes a series of multimodal generation models NUWA (NUWA, NUWA-LIP, NUWA-Infinity, NUWA-3D, NUWA-XL) and Step-Video (Step-Video-T2V, Step-Video-TI2V), a series of multimodal understanding models (KD-VLP, Bridge-Tower), and multimodal dialogue systems (Visual ChatGPT, TaskMatrix.AI). He published several papers in conferences such as CVPR, NeurIPS, ACL, ECCV, AAAI, MM, with more than 1000 citations. His Github open source projects have been liked more than 30,000 times.

吴晨飞，北京邮电大学博士，阿里巴巴通义实验室资深专家。研究方向为大模型预训练、多模态理解和生成。主要研究工作包括多模态生成模型 NUWA（女娲）系列（NUWA, NUWA-Infinity, NUWA-XL, DragNUWA）和Step-Video系列（Step-Video-T2V, Step-Video-TI2V）、多模态理解模型 Bridge Tower（桥塔）系列（KD-VLP, Bridge-Tower）以及多模态对话系统（Visual ChatGPT, TaskMatrix.AI）。在 CVPR, NeurIPS, ACL, ECCV, AAAI, MM 等会发表多篇论文，引用量5000余次, Github 开源项目获赞三万余次。


## Highlight

- **Multimodal Generation**: [GODIVA](https://arxiv.org/abs/2104.14806) (Preprint, 2021), [NUWA(女娲)](https://arxiv.org/abs/2111.12417) (ECCV, 2022, [![](https://img.shields.io/github/stars/microsoft/NUWA?style=social&label=Github+Stars)](https://github.com/microsoft/NUWA.git)), [NUWA-Infinity](https://arxiv.org/abs/2207.09814) (NeurIPS, 2022), [NUWA-LIP](https://arxiv.org/abs/2202.05009) (CVPR 2023), [NUWA-3D](https://arxiv.org/abs/2302.10781) (IJCAI 2023), [NUWA-XL](https://arxiv.org/abs/2303.12346) (ACL 2023), [DragNUWA](https://arxiv.org/abs/2308.08089) (Preprint, 2023), [LayoutNUWA](https://openreview.net/forum?id=qCUWVT0Ayy) (ICLR 2024), [StrokeNUWA](https://arxiv.org/abs/2401.17093) (Preprint, 2024), [Step-Video-T2V](https://arxiv.org/abs/2502.10248) (Preprint, 2025), [Step-Video-TI2V](https://arxiv.org/abs/2503.11251) (Preprint, 2025).
- **Multimodal Understanding**: [Bridge-Tower](https://arxiv.org/abs/2206.08657) (AAAI, 2023), [Manager-Tower](https://arxiv.org/abs/2306.00103) (ACL, 2023)
- **Multimodal System**: [Visual ChatGPT](https://arxiv.org/abs/2303.04671) (Preprint, 2023, [![](https://img.shields.io/github/stars/chenfei-wu/TaskMatrix?style=social&label=Github+Stars)](https://github.com/chenfei-wu/TaskMatrix)), [TaskMatrix.AI](https://arxiv.org/abs/2303.16434) (Intelligent Computing, 2024) [VL-InterpreT](https://openaccess.thecvf.com/content/CVPR2022/papers/Aflalo_VL-InterpreT_An_Interactive_Visualization_Tool_for_Interpreting_Vision-Language_Transformers_CVPR_2022_paper.pdf) (CVPR, 2022).

## Talks

- [NUWA: Neural visual world creation with multimodal pretraining](https://www.microsoft.com/en-us/research/video/research-talk-nuwa-neural-visual-world-creation-with-multimodal-pretraining/). Microsoft Research Summit 2021, October 2021.
- [VLP for Text-to-Image Synthesis](https://www.microsoft.com/en-us/research/video/vlp-tutorial-cvpr-2022-vlp-for-text-to-image-synthesis/). VLP Tutorial @ CVPR 2022, Jun 2022.
- [开放报名｜顶尖专家联合打造，首个系统化 AI 大模型前沿技术讲习班](https://mp.weixin.qq.com/s/z4cHRj0wv8CeJGEhXkFwNw). 智源社区, March 2023.
- [星辰大海 予力同行 遨游“AIGC+元宇宙”世界，掌行业风口，占赛道先机](https://mp.weixin.qq.com/s/CdgOuNL5dGXAx0xHizEvGw). 微软科技, March 2023.
- [中国中文信息学会《前沿技术讲习班》- 大模型系列专题 · 深圳站](https://mp.weixin.qq.com/s/lv8fKBf4jUq5hMpr_Vk1bw). 中国中文信息学会, Jun 2023.
- [A2M 峰会圆满落幕 AIGC 时代下的 AI 落地实践、数据智能和基础架构演进](https://mp.weixin.qq.com/s/0-NuH5qDe5afFmiBtdzgPQ). msup, Jun 2023.
- [MLNLP2023@多模态多语言大模型论坛](https://mp.weixin.qq.com/s/vB2zn0CTwO_iyda0OojbVw). MLNLP, Sep 2023.
- [中国中文信息学会《前沿技术讲习班》-大模型系列专题·成都站](https://mp.weixin.qq.com/s/F6CPgrGWSDUqMm2Nfg3ijQ). 中国中文信息学会, Nov 2023.

## Media Report

- [微软再扔 AI 聊天画图炸弹！视觉模型加持 ChatGPT，Visual ChatGPT 横空出世](https://mp.weixin.qq.com/s/Xg-MRtqBt6ONKnLJYFw0Ww). 新智元, March 2023.
- [视觉版 ChatGPT 来了！吸收 AI 画画全技能，MSRA 全华人团队打造，微软 16 年老将领衔](https://mp.weixin.qq.com/s/oanSkopLM93Krx2jVozR_A). 量子位, March 2023.
- [一个 AI 驱动百万个 API！微软提出多任务处理模型 TaskMatrix，机器人和物联网终于有救了](https://mp.weixin.qq.com/s/_mDyCiqSqlWi4zdtrfxOKw). 量子位, March 2023.
- [微软亚洲研究院多模态模型 NÜWA：以自然语言创造视觉内容](https://mp.weixin.qq.com/s/oyBSoGxJxMGuesO5ea4TxQ). 微软亚洲研究院, March 2022.
- [千万别让富坚义博看到这个-NUWA-Infinity](https://mp.weixin.qq.com/s/xiY0gGwN1V-uxUEIAFgJ7g). 量子位, Jul 2022.
- [NUWA 系列再添新成员——超长视频生成模型 NUWA-XL](https://mp.weixin.qq.com/s/1Ewuvtx4Hudu6s07GQ2Vyg). 微软亚洲研究院, Feb 2023.
- [带你穿越清明上河图！DragNUWA 惊艳亮相：一拖一拽让静图秒变视频](https://mp.weixin.qq.com/s/sgT5x-6rkFLqs4AEmBqyCw). 新智元, Sep 2023.

## Publications

### Multimodal Generation

- **Godiva: Generating open-domain videos from natural descriptions**. [![](https://img.shields.io/badge/Paper-378CE7)](https://arxiv.org/abs/2104.14806)
  <br> **Chenfei Wu**, Lun Huang, Qianxi Zhang, Binyang Li, Lei Ji, Fan Yang, Guillermo Sapiro, Nan Duan.
  <br> Arxiv, 2021

- **Nüwa: Visual synthesis pre-training for neural visual world creation**. [![](https://img.shields.io/badge/Paper-378CE7)](https://link.springer.com/chapter/10.1007/978-3-031-19787-1_41) [![](https://img.shields.io/github/stars/microsoft/NUWA?style=social&label=Github+Stars)](https://github.com/microsoft/NUWA.git)
  <br> **Chenfei Wu**, Jian Liang, Lei Ji, Fan Yang, Yuejian Fang, Daxin Jiang, Nan Duan.
  <br> ECCV, 2022.

- **NUWA-LIP: language-guided image inpainting with defect-free VQGAN**. [![](https://img.shields.io/badge/Paper-378CE7)](https://arxiv.org/abs/2202.05009)
  <br> Minheng Ni, **Chenfei Wu**, Haoyang Huang, Daxin Jiang, Wangmeng Zuo, Nan Duan.
  <br> CVPR 2023.

- **NUWA-Infinity: Autoregressive over autoregressive generation for infinite visual synthesis**. [![](https://img.shields.io/badge/Paper-378CE7)](https://proceedings.neurips.cc/paper_files/paper/2022/hash/6358cd0cd6607fdf4870595795eb1710-Abstract-Conference.html) [![](https://img.shields.io/badge/Homepage-FF8E8F)](https://nuwa-infinity.microsoft.com/#/NUWAInfinity) [![](https://img.shields.io/github/stars/microsoft/NUWA?style=social&label=Github+Stars)](https://github.com/microsoft/NUWA.git)
  <br> Jian Liang, **Chenfei Wu**, Xiaowei Hu, Zhe Gan, Jianfeng Wang, Lijuan Wang, Zicheng Liu, Yuejian Fang, Nan Duan.
  <br> CVPR 2022.

- **NUWA-XL: Diffusion over diffusion for extremely long video generation**. [![](https://img.shields.io/badge/Paper-378CE7)](https://arxiv.org/abs/2303.12346) [![](https://img.shields.io/badge/Homepage-FF8E8F)](https://nuwa-infinity.microsoft.com/#/NUWAXL) [![](https://img.shields.io/github/stars/microsoft/NUWA?style=social&label=Github+Stars)](https://github.com/microsoft/NUWA.git)
  <br> Shengming Yin, **Chenfei Wu**, Huan Yang, Jianfeng Wang, Xiaodong Wang, Minheng Ni, Zhengyuan Yang, Linjie Li, Shuguang Liu, Fan Yang, Jianlong Fu, Gong Ming, Lijuan Wang, Zicheng Liu, Houqiang Li, Nan Duan.
  <br> ACL 2023.

- **DragNUWA: Fine-grained control in video generation by integrating text, image, and trajectory**. [![](https://img.shields.io/badge/Paper-378CE7)](https://arxiv.org/abs/2308.08089) [![](https://img.shields.io/badge/Homepage-FF8E8F)](https://nuwa-infinity.microsoft.com/#/) [![](https://img.shields.io/github/stars/ProjectNUWA/DragNUWA?style=social&label=Github+Stars)](https://github.com/ProjectNUWA/DragNUWA)
  <br> Shengming Yin, **Chenfei Wu**, Jian Liang, Jie Shi, Houqiang Li, Gong Ming, Nan Duan.
  <br> Arxiv 2023.

- **StrokeNUWA: Tokenizing Strokes for Vector Graphic Synthesis**. [![](https://img.shields.io/badge/Paper-378CE7)](https://arxiv.org/abs/2401.17093)
  <br> Zecheng Tang, **Chenfei Wu**, Zekai Zhang, Mingheng Ni, Shengming Yin, Yu Liu, Zhengyuan Yang, Lijuan Wang, Zicheng Liu, Juntao Li, Nan Duan.
  <br> Arxiv 2024.

- **LayoutNUWA: Revealing the Hidden Layout Expertise of Large Language Models**. [![](https://img.shields.io/badge/Paper-378CE7)](https://openreview.net/forum?id=qCUWVT0Ayy) [![](https://img.shields.io/github/stars/ProjectNUWA/LayoutNUWA?style=social&label=Github+Stars)](https://github.com/ProjectNUWA/LayoutNUWA)
  <br> Zecheng Tang, **Chenfei Wu**, Juntao Li, Nan Duan.
  <br> ICLR 2024.

- **NUWA-3D: Learning 3D photography videos via self-supervised diffusion on single images**. [![](https://img.shields.io/badge/Paper-378CE7)](https://dl.acm.org/doi/abs/10.24963/ijcai.2023/167)
  <br> Xiaodong Wang, **Chenfei Wu**, Shengming Yin, Minheng Ni, Jianfeng Wang, Linjie Li, Zhengyuan Yang, Fan Yang, Lijuan Wang, Zicheng Liu, Yuejian Fang, Nan Duan.
  <br> IJCAI 2023.

- **HORIZON: A High-Resolution Panorama Synthesis Framework**. [![](https://img.shields.io/badge/Paper-378CE7)](https://dl.acm.org/doi/abs/10.24963/ijcai.2023/167)
  <br> Kun Yan, Lei Ji, **Chenfei Wu**, Jian Liang, Ming Zhou, Nan Duan, Shuai Ma.
  <br> AAAI 2024.

- **Trace Controlled Text to Image Generation**. [![](https://img.shields.io/badge/Paper-378CE7)](https://link.springer.com/chapter/10.1007/978-3-031-20059-5_4)
  <br> Kun Yan, Lei Ji, Chenfei Wu, Jianmin Bao, Ming Zhou, Nan Duan, Shuai Ma.
  <br> ECCV, 2022.

- **ORES: Open-vocabulary Responsible Visual Synthesis**. [![](https://img.shields.io/badge/Paper-378CE7)](https://arxiv.org/abs/2308.13785)
  <br> Minheng Ni, **Chenfei Wu**, Xiaodong Wang, Shengming Yin, Lijuan Wang, Zicheng Liu, Nan Duan.
  <br> AAAI 2024.

- **Reco: Region-controlled text-to-image generation**. [![](https://img.shields.io/badge/Paper-378CE7)](https://openaccess.thecvf.com/content/CVPR2023/html/Yang_ReCo_Region-Controlled_Text-to-Image_Generation_CVPR_2023_paper.html) [![](https://img.shields.io/github/stars/microsoft/ReCo?style=social&label=Github+Stars)](https://github.com/microsoft/ReCo)
  <br> Zhengyuan Yang, Jianfeng Wang, Zhe Gan, Linjie Li, Kevin Lin, **Chenfei Wu**, Nan Duan, Zicheng Liu, Ce Liu, Michael Zeng, Lijuan Wang.
  <br> CVPR, 2023.

- **DiVAE: Photorealistic images synthesis with denoising diffusion decoder**. [![](https://img.shields.io/badge/Paper-378CE7)](https://arxiv.org/abs/2206.00386)
  <br> Jie Shi, **Chenfei Wu**, Jian Liang, Xiang Liu, Nan Duan.
  <br> Arxiv 2022.

### Multimodal Understanding

- **Using Left and Right Brains Together: Towards Vision and Language Planning**. [![](https://img.shields.io/badge/Paper-378CE7)](https://arxiv.org/abs/2402.10534)
  <br> Jun Cen, Chenfei Wu, Xiao Liu, Shengming Yin, Yixuan Pei, Jinglong Yang, Qifeng Chen, Nan Duan, Jianguo Zhang.
  <br> Arxiv 2024.

- **Kd-vlp: Improving end-to-end vision-and-language pretraining with object knowledge distillation**. [![](https://img.shields.io/badge/Paper-378CE7)](https://arxiv.org/abs/2109.10504)
  <br> Yongfei Liu, Chenfei Wu, Shao-yen Tseng, Vasudev Lal, Xuming He, Nan Duan.
  <br> Findings of NAACL, 2022.

- **Bridgetower: Building bridges between encoders in vision-language representation learning**. [![](https://img.shields.io/badge/Paper-378CE7)](https://ojs.aaai.org/index.php/AAAI/article/view/26263) [![](https://img.shields.io/github/stars/microsoft/BridgeTower?style=social&label=Github+Stars)](https://github.com/microsoft/BridgeTower)
  <br> Xiao Xu, **Chenfei Wu**, Shachar Rosenman, Vasudev Lal, Wanxiang Che, Nan Duan.
  <br> AAAI 2023.

- **ManagerTower: Aggregating the insights of uni-modal experts for vision-language representation learning**. [![](https://img.shields.io/badge/Paper-378CE7)](https://aclanthology.org/2023.acl-long.811/)
  <br> Xiao Xu, Bei Li, **Chenfei Wu**, Shao-Yen Tseng, Anahita Bhiwandiwalla, Shachar Rosenman, Vasudev Lal, Wanxiang Che, Nan Duan.
  <br> ACL 2023.

- **Learning temporal video procedure segmentation from an automatically collected large dataset**. [![](https://img.shields.io/badge/Paper-378CE7)](https://openaccess.thecvf.com/content/WACV2022/html/Ji_Learning_Temporal_Video_Procedure_Segmentation_From_an_Automatically_Collected_Large_WACV_2022_paper.html)
  <br> Lei Ji, **Chenfei Wu**, Daisy Zhou, Kun Yan, Edward Cui, Xilin Chen, Nan Duan.
  <br> WACV 2022.

- **Deep reason: A strong baseline for real-world visual reasoning**. [![](https://img.shields.io/badge/Paper-378CE7)](https://arxiv.org/abs/1905.10226)
  <br> **Chenfei Wu**, Yanzhao Zhou, Gen Li, Nan Duan, Duyu Tang, Xiaojie Wang.
  <br> CVPR VQA Workshop, 2019.
- **Object-difference attention: A simple relational attention for visual question answering**. [![](https://img.shields.io/badge/Paper-378CE7)](https://dl.acm.org/doi/abs/10.1145/3240508.3240513)
  <br> **Chenfei Wu**, Jinlai Liu, Xiaojie Wang, Xuan Dong
  <br> ACM Multimedia, 2018

- **Chain of reasoning for visual question answering**. [![](https://img.shields.io/badge/Paper-378CE7)](https://proceedings.neurips.cc/paper_files/paper/2018/hash/31fefc0e570cb3860f2a6d4b38c6490d-Abstract.html)
  <br> **Chenfei Wu**, Jinlai Liu, Xiaojie Wang, Xuan Dong.
  <br> NeurIPS, 2018

- **Differential networks for visual question answering**. [![](https://img.shields.io/badge/Paper-378CE7)](https://ojs.aaai.org/index.php/AAAI/article/view/4930)
  <br>**Chenfei Wu**, Jinlai Liu, Xiaojie Wang, Ruifan Li.
  <br> AAAI, 2019.

- **Sequential visual reasoning for visual question answering**. [![](https://img.shields.io/badge/Paper-378CE7)](https://ieeexplore.ieee.org/abstract/document/8691361/)
  <br> Jinlai Liu, Chenfei Wu, Xiaojie Wang, Xuan Dong.
  <br> CCIS 2018.

### Multimodal Systems/Evaluations

- **Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models**. [![](https://img.shields.io/badge/Paper-378CE7)](https://arxiv.org/abs/2303.04671) [![](https://img.shields.io/github/stars/chenfei-wu/TaskMatrix?style=social&label=Github+Stars)](https://github.com/chenfei-wu/TaskMatrix)
  <br> **Chenfei Wu**, Shengming Yin, Weizhen Qi, Xiaodong Wang, Zecheng Tang, Nan Duan.
  <br> arXiv, 2023.

- **Taskmatrix. ai: Completing tasks by connecting foundation models with millions of apis**. [![](https://img.shields.io/badge/Paper-378CE7)](https://arxiv.org/abs/2303.16434) [![](https://img.shields.io/github/stars/chenfei-wu/TaskMatrix?style=social&label=Github+Stars)](https://github.com/chenfei-wu/TaskMatrix)
  <br> Yaobo Liang, **Chenfei Wu**, Ting Song, Wenshan Wu, Yan Xia, Yu Liu, Yang Ou, Shuai Lu, Lei Ji, Shaoguang Mao, Yun Wang, Linjun Shou, Ming Gong, Nan Duan.
  <br> Intelligent Computing, 2024

- **Vl-interpret: An interactive visualization tool for interpreting vision-language transformers**. [![](https://img.shields.io/badge/Paper-378CE7)](https://openaccess.thecvf.com/content/CVPR2022/html/Aflalo_VL-InterpreT_An_Interactive_Visualization_Tool_for_Interpreting_Vision-Language_Transformers_CVPR_2022_paper.html)
  <br> Estelle Aflalo, Meng Du, Shao-Yen Tseng, Yongfei Liu, **Chenfei Wu**, Nan Duan, Vasudev Lal.
  <br> CVPR 2022.

- **Low-code llm: Visual programming over llms**. [![](https://img.shields.io/badge/Paper-378CE7)](https://arxiv.org/abs/2304.08103)
  <br> Yuzhe Cai, Shaoguang Mao, Wenshan Wu, Zehua Wang, Yaobo Liang, Tao Ge, **Chenfei Wu**, Wang You, Ting Song, Yan Xia, Jonathan Tien, Nan Duan.
  <br> Arxiv 2023.

- **Learning to program with natural language**. [![](https://img.shields.io/badge/Paper-378CE7)](https://arxiv.org/abs/2304.10464)
  <br> Yiduo Guo, Yaobo Liang, **Chenfei Wu**, Wenshan Wu, Dongyan Zhao, Nan Duan.
  <br> Arxiv 2023.

- **GEM: A general evaluation benchmark for multimodal tasks**. [![](https://img.shields.io/badge/Paper-378CE7)](https://arxiv.org/abs/2106.09889)
  <br> Lin Su, Nan Duan, Edward Cui, Lei Ji, **Chenfei Wu**, Huaishao Luo, Yongfei Liu, Ming Zhong, Taroon Bharti, Arun Sacheti.
  <br> Findings of ACL, 2021.

- **EIPE-text: Evaluation-Guided Iterative Plan Extraction for Long-Form Narrative Text Generation**. [![](https://img.shields.io/badge/Paper-378CE7)](https://arxiv.org/abs/2310.08185)
  <br> Wang You, Wenshan Wu, Yaobo Liang, Shaoguang Mao, **Chenfei Wu**, Maosong Cao, Yuzhe Cai, Yiduo Guo, Yan Xia, Furu Wei, Nan Duan.
  <br> Arxiv 2023.

- **GameEval: Evaluating LLMs on Conversational Games**. [![](https://img.shields.io/badge/Paper-378CE7)](https://arxiv.org/abs/2402.10534)
  <br> Dan Qiao, Chenfei Wu, Yaobo Liang, Juntao Li, Nan Duan.
  <br> Arxiv 2023.
